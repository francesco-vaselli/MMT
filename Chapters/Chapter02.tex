%*****************************************
\chapter{Deep Learning and Generative Models}\label{ch:dlgm}
%*****************************************
%Acronym testing: \ac{UML} -- \acs{UML} -- \acf{UML} -- \acp{UML}
\begin{flushright}{\slshape
        By far, the greatest danger of Artificial Intelligence \\
        is that people conclude too early that they understand it.} \\ \medskip
    --- Eliezer Yudkowsky
\end{flushright}

In recent years, \emph{machine learning} techniques have been massively adopted by scientific collaboration around the world. In particular, a paradigm known as \emph{Deep Learning}, which leverages multiple layers of \emph{artificial neurons} trained through the use of a \emph{loss function} and \emph{backpropagation}, has achieved a wide range of applications.
The present chapter will give to the reader a concise but hopefully complete overview of the building blocks behind the recent success of Deep Learning. Towards the conclusion we turn to the class of \emph{generative models}, paving the way for the next chapter discussion.
	

\section{Neural Networks}


\subsection{The Perceptron}
\graffito{Note: The content of this chapter is just some dummy text.
It is not a real language.}


\subsection{Activation Functions}

\subsection{Loss functions and Backpropagation}

\subsection{Deep Learning}
% also mention problems?

\section{Generative Models}

\subsection{State of the art}

\subsection{Known issues}


%*****************************************
%*****************************************
%*****************************************
%*****************************************
%*****************************************
